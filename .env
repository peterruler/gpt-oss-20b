# Ollama Configuration
OLLAMA_HOST=http://localhost:11434
OLLAMA_MODEL=gpt-oss:20b

# Chainlit Configuration  
CHAINLIT_HOST=localhost
CHAINLIT_PORT=8000
