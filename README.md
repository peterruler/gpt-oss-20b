# GPT-OSS:20B Streamlit Chat

Eine interaktive Chat-Anwendung mit dem GPT-OSS:20B Modell Ã¼ber Ollama und Streamlit.

## Screenshot

![GPT-OSS:20B Chat Interface](_Project/Screenshot.png)

## Voraussetzungen

- Python 3.8+
- Ollama installiert und laufend
- Das GPT-OSS:20B Modell in Ollama verfÃ¼gbar

## Installation

1. **Repository navigieren:**
   ```bash
   # Navigieren Sie zu Ihrem Projekt-Ordner
   cd ~/Documents/Projects/gpt-oss-20b
   # oder verwenden Sie den vollstÃ¤ndigen Pfad zu Ihrem Projekt
   ```

2. **Virtuelle Umgebung aktivieren:**
   ```bash
   source .venv/bin/activate
   ```

3. **AbhÃ¤ngigkeiten sind bereits installiert** (streamlit, ollama, python-dotenv)

## Neue Installation (falls erforderlich)

Falls Sie das Projekt an einem anderen Ort einrichten mÃ¶chten:

```bash
# 1. Projekt-Ordner erstellen und navigieren
mkdir -p ~/Documents/Projects/gpt-oss-20b
cd ~/Documents/Projects/gpt-oss-20b

# 2. Virtuelle Umgebung erstellen
python -m venv .venv

# 3. Virtuelle Umgebung aktivieren
source .venv/bin/activate

# 4. AbhÃ¤ngigkeiten installieren
pip install streamlit ollama python-dotenv

# 5. .env Datei erstellen (siehe Konfiguration unten)
```

## Ollama Setup

1. **Ollama starten:**
   ```bash
   ollama serve
   ```

2. **GPT-OSS:20B Modell herunterladen:**
   ```bash
   ollama pull gpt-oss:20b
   ```

3. **VerfÃ¼gbare Modelle prÃ¼fen:**
   ```bash
   ollama list
   ```

## Konfiguration

Die Konfiguration erfolgt Ã¼ber die `.env` Datei:

```env
# Ollama Configuration
OLLAMA_HOST=http://localhost:11434
OLLAMA_MODEL=gpt-oss:20b

# Streamlit Configuration  
STREAMLIT_HOST=localhost
STREAMLIT_PORT=8501
```

## Anwendung starten

### Einfach starten
```bash
./start.sh
```
Das Script findet automatisch einen verfÃ¼gbaren Port (startet bei 8501)

### Manuell starten
```bash
source .venv/bin/activate
streamlit run app.py --server.port 8501
```

Die Anwendung ist dann verfÃ¼gbar unter: **http://localhost:8501** (oder dem nÃ¤chsten verfÃ¼gbaren Port)

## Features

- ğŸ¤– **Streaming Chat**: Echtzeitantworten vom GPT-OSS:20B Modell
- ğŸ›ï¸ **Parameter-Kontrolle**: Temperatur und andere Einstellungen anpassbar
- ğŸ’¬ **Chat-Verlauf**: Automatische Speicherung wÃ¤hrend der Session
- ğŸ“Š **Live-Statistiken**: Nachrichten, Zeichen, Session-Dauer
- ğŸ”„ **Modell-Management**: Automatische PrÃ¼fung und Laden von Modellen
- ğŸ—‘ï¸ **Chat-Kontrolle**: Chat lÃ¶schen und neu starten
- âš¡ **Fehlerbehandlung**: Automatische ÃœberprÃ¼fung der ModellverfÃ¼gbarkeit
- ğŸ¨ **Moderne UI**: Streamlit-basierte, benutzerfreundliche OberflÃ¤che

## Projektstruktur

```
gpt-oss-20b/
â”œâ”€â”€ app.py               # Haupt-Streamlit-Anwendung
â”œâ”€â”€ requirements.txt     # Python-AbhÃ¤ngigkeiten
â”œâ”€â”€ .env                # Umgebungsvariablen
â”œâ”€â”€ start.sh            # Startup-Script
â””â”€â”€ README.md           # Diese Datei
```

## Anpassung

### Modell Ã¤ndern
Bearbeiten Sie die `.env` Datei und Ã¤ndern Sie `OLLAMA_MODEL` zu einem anderen verfÃ¼gbaren Modell.

### Port Ã¤ndern
```bash
streamlit run app.py --server.port 8080
```

### Parameter anpassen
Nutzen Sie die Sidebar in der Streamlit-App fÃ¼r:
- Temperatur (0.0 - 2.0)
- Live-Statistiken
- Chat-Management

## Fehlerbehebung

### Ollama nicht erreichbar
```bash
# PrÃ¼fen ob Ollama lÃ¤uft
curl http://localhost:11434/api/tags

# Ollama neu starten
ollama serve
```

### Modell nicht verfÃ¼gbar
```bash
# Modell herunterladen
ollama pull gpt-oss:20b

# VerfÃ¼gbare Modelle auflisten  
ollama list
```

### Port bereits belegt
```bash
# Anderen Port verwenden
streamlit run app.py --server.port 8502
```

### Watchdog-Performance-Warnung
```bash
# Optional fÃ¼r bessere Performance
xcode-select --install
pip install watchdog
```

## Lizenz

MIT License

# Screenshot
